{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df_ibex = pd.read_csv('data/ibex.csv')\n",
    "\n",
    "# Convert the 'date' column to datetime if it's not already in datetime format\n",
    "df_ibex['Date'] = pd.to_datetime(df_ibex['Date'])\n",
    "\n",
    "# Set the 'date' column as the index\n",
    "df_ibex.set_index('Date', inplace=True)\n",
    "\n",
    "# Drop 'Volume' and 'Adj Close' columns\n",
    "df_ibex = df_ibex.drop(['Volume', 'Adj Close'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-03</th>\n",
       "      <td>9899.400391</td>\n",
       "      <td>9993.599609</td>\n",
       "      <td>9850.500000</td>\n",
       "      <td>9888.299805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>9895.500000</td>\n",
       "      <td>9974.200195</td>\n",
       "      <td>9799.400391</td>\n",
       "      <td>9888.400391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>9877.500000</td>\n",
       "      <td>9882.400391</td>\n",
       "      <td>9599.299805</td>\n",
       "      <td>9801.400391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>9803.200195</td>\n",
       "      <td>9832.599609</td>\n",
       "      <td>9678.400391</td>\n",
       "      <td>9702.700195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>9682.400391</td>\n",
       "      <td>9699.400391</td>\n",
       "      <td>9497.799805</td>\n",
       "      <td>9560.700195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>9650.200195</td>\n",
       "      <td>9670.900391</td>\n",
       "      <td>9639.000000</td>\n",
       "      <td>9659.599609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>9632.099609</td>\n",
       "      <td>9661.799805</td>\n",
       "      <td>9607.799805</td>\n",
       "      <td>9661.799805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>9673.000000</td>\n",
       "      <td>9700.500000</td>\n",
       "      <td>9657.500000</td>\n",
       "      <td>9700.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>9672.500000</td>\n",
       "      <td>9682.099609</td>\n",
       "      <td>9612.599609</td>\n",
       "      <td>9612.599609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>9564.900391</td>\n",
       "      <td>9564.900391</td>\n",
       "      <td>9518.500000</td>\n",
       "      <td>9549.200195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close\n",
       "Date                                                          \n",
       "2011-01-03  9899.400391  9993.599609  9850.500000  9888.299805\n",
       "2011-01-04  9895.500000  9974.200195  9799.400391  9888.400391\n",
       "2011-01-05  9877.500000  9882.400391  9599.299805  9801.400391\n",
       "2011-01-06  9803.200195  9832.599609  9678.400391  9702.700195\n",
       "2011-01-07  9682.400391  9699.400391  9497.799805  9560.700195\n",
       "...                 ...          ...          ...          ...\n",
       "2019-12-23  9650.200195  9670.900391  9639.000000  9659.599609\n",
       "2019-12-24  9632.099609  9661.799805  9607.799805  9661.799805\n",
       "2019-12-27  9673.000000  9700.500000  9657.500000  9700.500000\n",
       "2019-12-30  9672.500000  9682.099609  9612.599609  9612.599609\n",
       "2019-12-31  9564.900391  9564.900391  9518.500000  9549.200195\n",
       "\n",
       "[2299 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ibex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split date\n",
    "split_date = pd.to_datetime('2019-01-01')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data = df_ibex[df_ibex.index < split_date]\n",
    "test_data = df_ibex[df_ibex.index >= split_date]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_x(df, time_window):\n",
    "    data_raw = np.array(df)  # convert to numpy array\n",
    "    data = []\n",
    "\n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - time_window):\n",
    "        data.append(data_raw[index: index + time_window].reshape(-1))\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    out = data\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_y(df, time_window):\n",
    "    df = df['Close']\n",
    "    data_raw = np.array(df)  # convert to numpy array\n",
    "    data = []\n",
    "\n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - time_window):\n",
    "        data.append(data_raw[index + time_window])\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    out = data\n",
    "    out = np.expand_dims(out, axis=1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = split_data_x(train_data, time_window )\n",
    "y_train = split_data_y(train_data, time_window)\n",
    "x_test = split_data_x(test_data, time_window)\n",
    "y_test = split_data_y(test_data, time_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input & Output Shape of Train & Test Data:\n",
      "x_train.shape =  (2034, 40)\n",
      "y_train.shape =  (2034, 1)\n",
      "x_test.shape =  (245, 40)\n",
      "y_test.shape =  (245, 1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(price_x,price,test_size=0.3,shuffle=False)\n",
    "print('\\nInput & Output Shape of Train & Test Data:')\n",
    "print('x_train.shape = ',x_train.shape)\n",
    "print('y_train.shape = ',y_train.shape)\n",
    "print('x_test.shape = ',x_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the linear regression model\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = regression_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 70.7192571196334\n"
     ]
    }
   ],
   "source": [
    "# Calculate the root mean squared error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error (RMSE):', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Plotting the predicted values and real values\u001b[39;00m\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m plt\u001b[39m.\u001b[39mplot(y_test\u001b[39m.\u001b[39;49mindex, y_test, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReal Values\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mplot(y_pred\u001b[39m.\u001b[39mindex, y_pred, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPredicted Values\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the predicted values and real values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.index, y_test, label='Real Values')\n",
    "plt.plot(y_pred.index, y_pred, label='Predicted Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('Linear Regression - Predicted vs Real Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x[:, -1] # Output only the last column (close price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters\n",
    "w = 6  # Number of input data points (lookback_window)\n",
    "h = 1  # Number of future price points to predict (horizon)\n",
    "hidden_size = 16\n",
    "lr = 0.001\n",
    "num_iterations = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df_ibex_train[['Open', 'Close', 'High', 'Low']])\n",
    "\n",
    "# Convert the scaled data to PyTorch tensors\n",
    "tensor_data = torch.FloatTensor(scaled_data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the input and target sequences for training\n",
    "input_sequences = []\n",
    "target_sequences = []\n",
    "for i in range(len(tensor_data) - w - h):\n",
    "    input_sequences.append(tensor_data[i:i+w])\n",
    "    target_sequences.append(tensor_data[i+w+h-1, 1])\n",
    "\n",
    "# Create tensors for input and target sequences\n",
    "x_train = torch.stack(input_sequences).to(device)\n",
    "y_train = torch.stack(target_sequences).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "input_size = x_train.size(-1)\n",
    "output_size = 1\n",
    "model = ANN(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamidrezarahimzadeh/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2037])) that is different to the input size (torch.Size([2037, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100, Loss: 0.04446214437484741\n",
      "Iteration: 200, Loss: 0.04043450206518173\n",
      "Iteration: 300, Loss: 0.039052631705999374\n",
      "Iteration: 400, Loss: 0.03876839578151703\n",
      "Iteration: 500, Loss: 0.03872628137469292\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for iteration in range(num_iterations):\n",
    "    # Forward pass\n",
    "    output = model(x_train)\n",
    "    loss = criterion(output, y_train)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss\n",
    "    if (iteration + 1) % 100 == 0:\n",
    "        print(f'Iteration: {iteration + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions on the training data\n",
    "predicted_data = model(x_train)\n",
    "predicted_data = predicted_data.cpu().detach().numpy()\n",
    "\n",
    "# Inverse transform the target data\n",
    "y_train = y_train.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.16694113612174988\n",
      "RMSE: 0.19499312341213226\n",
      "sMAPE: 0.28301321977805227\n",
      "MAPE: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bj/_987g_v95g79pn481z7wtctw0000gn/T/ipykernel_8967/425520663.py:5: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.abs((y_train - predicted_data) / y_train).mean()\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_train, predicted_data)\n",
    "rmse = mean_squared_error(y_train, predicted_data, squared=False)\n",
    "smape = 2 * mae / (np.abs(y_train) + np.abs(predicted_data)).mean()\n",
    "mape = np.abs((y_train - predicted_data) / y_train).mean()\n",
    "\n",
    "# Print the metrics\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'sMAPE: {smape}')\n",
    "print(f'MAPE: {mape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
